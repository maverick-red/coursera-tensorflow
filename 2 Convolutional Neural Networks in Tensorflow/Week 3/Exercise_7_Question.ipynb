{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "name": "python2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 11543
        },
        "outputId": "b43b844a-6d4d-4f62-a45e-b16eb9dbe1a6"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3), include_top=False, weights=None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 17:55:46--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   178MB/s    in 0.5s    \n",
            "\n",
            "2019-05-11 17:55:47 (178 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcd93501-9ebc-4380-f056-015c0bbb63bc"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('last layer output shape: ', (None, 7, 7, 768))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8449
        },
        "outputId": "bd88e0ea-a08f-420a-a790-c7cf0789e199"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model(pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics = ['acc']\n",
        "             )\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 150, 150, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1024)         38536192    flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            1025        dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "8a8dc6bb-7240-49b2-e43e-ddcf40111e5e"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-05-11 17:59:59--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   123MB/s    in 1.2s    \n",
            "\n",
            "2019-05-11 18:00:00 (123 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2019-05-11 18:00:01--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.141.128, 2607:f8b0:400c:c06::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.141.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-05-11 18:00:02 (101 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2e8ee242-a52f-4d52-9f1b-3d9e6fa82219"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "train_horses_dir = os.path.join(train_dir, 'horses') # Directory with our training horse pictures\n",
        "train_humans_dir = os.path.join(train_dir, 'humans') # Directory with our training humans pictures\n",
        "validation_horses_dir = os.path.join(validation_dir, 'horses') # Directory with our validation horse pictures\n",
        "validation_humans_dir = os.path.join(validation_dir, 'humans')# Directory with our validation humanas pictures\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horses_dir)\n",
        "train_humans_fnames = os.listdir(train_humans_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
        "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c50d8a75-fbe8-4bfa-8c98-98216033d9cd"
      },
      "source": [
        "# Add our data-augmentation parameters to ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range = 40,\n",
        "                                   width_shift_range = 0.2,\n",
        "                                   height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True\n",
        "                                  )\n",
        "\n",
        "# Note that the validation data should not be augmented!\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size = 20,\n",
        "                                                    class_mode = 'binary', \n",
        "                                                    target_size = (150, 150))     \n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = 'binary', \n",
        "                                                          target_size = (150, 150))\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3162
        },
        "outputId": "eb717dd6-a857-4138-ecb6-cc16b086ef33"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "            train_generator,\n",
        "            validation_data = validation_generator,\n",
        "            steps_per_epoch = 100,\n",
        "            epochs = 100,\n",
        "            validation_steps = 50,\n",
        "            verbose = 2,\n",
        "            callbacks=[callbacks])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - 2s 176ms/step - loss: 0.0451 - acc: 0.9805\n",
            " - 16s - loss: 0.2585 - acc: 0.8978 - val_loss: 0.0451 - val_acc: 0.9805\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 0.0915 - acc: 0.9688\n",
            " - 12s - loss: 0.1230 - acc: 0.9533 - val_loss: 0.0915 - val_acc: 0.9688\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.0026 - acc: 1.0000\n",
            " - 12s - loss: 0.1047 - acc: 0.9669 - val_loss: 0.0026 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.0099 - acc: 0.9961\n",
            " - 13s - loss: 0.0613 - acc: 0.9766 - val_loss: 0.0099 - val_acc: 0.9961\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 0.0271 - acc: 0.9922\n",
            " - 12s - loss: 0.0435 - acc: 0.9864 - val_loss: 0.0271 - val_acc: 0.9922\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.1287 - acc: 0.9766\n",
            " - 12s - loss: 0.0240 - acc: 0.9912 - val_loss: 0.1287 - val_acc: 0.9766\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.0882 - acc: 0.9805\n",
            " - 12s - loss: 0.0664 - acc: 0.9796 - val_loss: 0.0882 - val_acc: 0.9805\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.1033 - acc: 0.9844\n",
            " - 13s - loss: 0.0298 - acc: 0.9883 - val_loss: 0.1033 - val_acc: 0.9844\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.0815 - acc: 0.9844\n",
            " - 12s - loss: 0.0420 - acc: 0.9922 - val_loss: 0.0815 - val_acc: 0.9844\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - 2s 120ms/step - loss: 0.1746 - acc: 0.9688\n",
            " - 12s - loss: 0.0282 - acc: 0.9893 - val_loss: 0.1746 - val_acc: 0.9688\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - 2s 131ms/step - loss: 0.0580 - acc: 0.9922\n",
            " - 13s - loss: 0.0499 - acc: 0.9893 - val_loss: 0.0580 - val_acc: 0.9922\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.1820 - acc: 0.9688\n",
            " - 12s - loss: 0.0546 - acc: 0.9854 - val_loss: 0.1820 - val_acc: 0.9688\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - 1s 115ms/step - loss: 0.1004 - acc: 0.9844\n",
            " - 12s - loss: 0.0298 - acc: 0.9883 - val_loss: 0.1004 - val_acc: 0.9844\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.1270 - acc: 0.9805\n",
            " - 12s - loss: 0.0450 - acc: 0.9873 - val_loss: 0.1270 - val_acc: 0.9805\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.1351 - acc: 0.9844\n",
            " - 12s - loss: 0.0322 - acc: 0.9932 - val_loss: 0.1351 - val_acc: 0.9844\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - 1s 115ms/step - loss: 0.1244 - acc: 0.9844\n",
            " - 12s - loss: 0.0223 - acc: 0.9912 - val_loss: 0.1244 - val_acc: 0.9844\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.1534 - acc: 0.9805\n",
            " - 13s - loss: 0.0232 - acc: 0.9932 - val_loss: 0.1534 - val_acc: 0.9805\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.2658 - acc: 0.9648\n",
            " - 12s - loss: 0.0334 - acc: 0.9912 - val_loss: 0.2658 - val_acc: 0.9648\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.2293 - acc: 0.9648\n",
            " - 12s - loss: 0.0086 - acc: 0.9981 - val_loss: 0.2293 - val_acc: 0.9648\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.1103 - acc: 0.9805\n",
            " - 12s - loss: 0.0429 - acc: 0.9873 - val_loss: 0.1103 - val_acc: 0.9805\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - 2s 115ms/step - loss: 0.5051 - acc: 0.9531\n",
            " - 12s - loss: 0.0174 - acc: 0.9951 - val_loss: 0.5051 - val_acc: 0.9531\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.1364 - acc: 0.9727\n",
            " - 12s - loss: 0.0809 - acc: 0.9864 - val_loss: 0.1364 - val_acc: 0.9727\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.1783 - acc: 0.9688\n",
            " - 12s - loss: 0.0167 - acc: 0.9922 - val_loss: 0.1783 - val_acc: 0.9688\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - 1s 115ms/step - loss: 0.2074 - acc: 0.9688\n",
            " - 13s - loss: 0.0378 - acc: 0.9903 - val_loss: 0.2074 - val_acc: 0.9688\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - 2s 115ms/step - loss: 0.4439 - acc: 0.9570\n",
            " - 12s - loss: 0.0128 - acc: 0.9961 - val_loss: 0.4439 - val_acc: 0.9570\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.3035 - acc: 0.9688\n",
            " - 12s - loss: 0.0164 - acc: 0.9942 - val_loss: 0.3035 - val_acc: 0.9688\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 0.2321 - acc: 0.9727\n",
            " - 12s - loss: 0.0301 - acc: 0.9912 - val_loss: 0.2321 - val_acc: 0.9727\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.3495 - acc: 0.9688\n",
            " - 12s - loss: 0.0115 - acc: 0.9951 - val_loss: 0.3495 - val_acc: 0.9688\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.3585 - acc: 0.9688\n",
            " - 12s - loss: 0.0307 - acc: 0.9951 - val_loss: 0.3585 - val_acc: 0.9688\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.2525 - acc: 0.9648\n",
            " - 12s - loss: 0.0083 - acc: 0.9971 - val_loss: 0.2525 - val_acc: 0.9648\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.2394 - acc: 0.9688\n",
            " - 13s - loss: 0.0168 - acc: 0.9922 - val_loss: 0.2394 - val_acc: 0.9688\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - 1s 111ms/step - loss: 0.2603 - acc: 0.9688\n",
            " - 12s - loss: 0.0253 - acc: 0.9932 - val_loss: 0.2603 - val_acc: 0.9688\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - 2s 129ms/step - loss: 0.0961 - acc: 0.9844\n",
            " - 13s - loss: 0.0135 - acc: 0.9932 - val_loss: 0.0961 - val_acc: 0.9844\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.2245 - acc: 0.9688\n",
            " - 12s - loss: 0.0107 - acc: 0.9971 - val_loss: 0.2245 - val_acc: 0.9688\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - 1s 115ms/step - loss: 0.0906 - acc: 0.9844\n",
            " - 12s - loss: 0.0273 - acc: 0.9932 - val_loss: 0.0906 - val_acc: 0.9844\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - 2s 125ms/step - loss: 0.0705 - acc: 0.9922\n",
            " - 12s - loss: 0.0295 - acc: 0.9893 - val_loss: 0.0705 - val_acc: 0.9922\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.0473 - acc: 0.9961\n",
            " - 13s - loss: 0.0080 - acc: 0.9961 - val_loss: 0.0473 - val_acc: 0.9961\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.0761 - acc: 0.9883\n",
            " - 12s - loss: 0.0195 - acc: 0.9961 - val_loss: 0.0761 - val_acc: 0.9883\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - 2s 118ms/step - loss: 0.2254 - acc: 0.9727\n",
            " - 12s - loss: 0.0225 - acc: 0.9942 - val_loss: 0.2254 - val_acc: 0.9727\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - 2s 115ms/step - loss: 0.3457 - acc: 0.9688\n",
            " - 12s - loss: 0.0430 - acc: 0.9922 - val_loss: 0.3457 - val_acc: 0.9688\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.3666 - acc: 0.9727\n",
            " - 12s - loss: 0.0366 - acc: 0.9922 - val_loss: 0.3666 - val_acc: 0.9727\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - 2s 117ms/step - loss: 0.3501 - acc: 0.9727\n",
            " - 12s - loss: 0.0201 - acc: 0.9951 - val_loss: 0.3501 - val_acc: 0.9727\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.3526 - acc: 0.9727\n",
            " - 12s - loss: 0.0296 - acc: 0.9912 - val_loss: 0.3526 - val_acc: 0.9727\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.5788 - acc: 0.9492\n",
            " - 13s - loss: 0.0190 - acc: 0.9971 - val_loss: 0.5788 - val_acc: 0.9492\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - 1s 114ms/step - loss: 0.3073 - acc: 0.9727\n",
            " - 12s - loss: 0.0093 - acc: 0.9981 - val_loss: 0.3073 - val_acc: 0.9727\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - 1s 115ms/step - loss: 0.2769 - acc: 0.9688\n",
            " - 12s - loss: 0.0107 - acc: 0.9961 - val_loss: 0.2769 - val_acc: 0.9688\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - 1s 115ms/step - loss: 0.2753 - acc: 0.9688\n",
            " - 12s - loss: 0.0072 - acc: 0.9981 - val_loss: 0.2753 - val_acc: 0.9688\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - 2s 126ms/step - loss: 0.2584 - acc: 0.9688\n",
            " - 12s - loss: 0.0306 - acc: 0.9942 - val_loss: 0.2584 - val_acc: 0.9688\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - 2s 119ms/step - loss: 0.2117 - acc: 0.9727\n",
            " - 12s - loss: 0.0083 - acc: 0.9971 - val_loss: 0.2117 - val_acc: 0.9727\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - 2s 127ms/step - loss: 0.3342 - acc: 0.9609\n",
            " - 12s - loss: 0.0076 - acc: 0.9981 - val_loss: 0.3342 - val_acc: 0.9609\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - 1s 115ms/step - loss: 0.3105 - acc: 0.9609\n",
            " - 12s - loss: 0.0073 - acc: 0.9981 - val_loss: 0.3105 - val_acc: 0.9609\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.3353 - acc: 0.9609\n",
            " - 12s - loss: 0.0136 - acc: 0.9912 - val_loss: 0.3353 - val_acc: 0.9609\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.1770 - acc: 0.9766\n",
            " - 12s - loss: 0.0274 - acc: 0.9942 - val_loss: 0.1770 - val_acc: 0.9766\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.3179 - acc: 0.9648\n",
            " - 12s - loss: 0.0130 - acc: 0.9961 - val_loss: 0.3179 - val_acc: 0.9648\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - 1s 112ms/step - loss: 0.7280 - acc: 0.9453\n",
            " - 12s - loss: 0.0032 - acc: 0.9981 - val_loss: 0.7280 - val_acc: 0.9453\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - 2s 116ms/step - loss: 0.3722 - acc: 0.9570\n",
            " - 12s - loss: 0.0066 - acc: 0.9971 - val_loss: 0.3722 - val_acc: 0.9570\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - 2s 134ms/step - loss: 0.3015 - acc: 0.9648\n",
            " - 13s - loss: 0.0102 - acc: 0.9971 - val_loss: 0.3015 - val_acc: 0.9648\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - 2s 121ms/step - loss: 0.7047 - acc: 0.9453\n",
            " - 12s - loss: 0.0103 - acc: 0.9981 - val_loss: 0.7047 - val_acc: 0.9453\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - 2s 122ms/step - loss: 0.4325 - acc: 0.9609\n",
            " - 13s - loss: 0.0223 - acc: 0.9951 - val_loss: 0.4325 - val_acc: 0.9609\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - 1s 113ms/step - loss: 0.4297 - acc: 0.9609\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            " - 12s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.4297 - val_acc: 0.9609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "e4532443-0791-4f9b-9e4a-7fd3c2936ddd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfUmKyBu044vX2vcvqwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}